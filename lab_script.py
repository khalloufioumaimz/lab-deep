# lab_script.py - Version pour d√©butants

# ============ PARTIE 1 : IMPORT DES BIBLIOTH√àQUES ============
print("üîß Importation des biblioth√®ques...")
import torch
import librosa
import numpy as np
import matplotlib.pyplot as plt
from transformers import pipeline
import warnings
warnings.filterwarnings('ignore')

print("‚úÖ Biblioth√®ques import√©es avec succ√®s!")

# ============ PARTIE 2 : CONFIGURATION SIMPLE ============
print("\n‚öôÔ∏è Configuration du lab...")

# Choix du mod√®le (commencez avec 'small' c'est un bon compromis)
MODEL_CHOICE = "openai/whisper-small"  # Essayez aussi: "openai/whisper-tiny" pour plus rapide

# Chemin vers vos fichiers
AUDIO_FILES = ["audio/test1.wav", "audio/test2.wav", "audio/test3.wav"]
REF_FILES = ["references/test1.txt", "references/test2.txt", "references/test3.txt"]

print(f"Mod√®le s√©lectionn√©: {MODEL_CHOICE}")
print(f"Nombre de fichiers: {len(AUDIO_FILES)}")

# ============ PARTIE 3 : CHARGER UN MOD√àLE WHISPER SIMPLE ============
print("\nü§ñ Chargement du mod√®le Whisper...")

# Cette m√©thode est plus simple pour d√©buter
transcriber = pipeline(
    "automatic-speech-recognition",
    model=MODEL_CHOICE,
    device="cpu"  # Mettez "cuda:0" si vous avez une carte graphique NVIDIA
)

print("‚úÖ Mod√®le Whisper charg√©!")

# ============ PARTIE 4 : FONCTION POUR LIRE LES FICHIERS ============
def lire_fichier_audio(chemin):
    """Lit un fichier audio et le pr√©pare pour Whisper"""
    print(f"üéµ Lecture de: {chemin}")
    
    # Charger l'audio
    audio, sr = librosa.load(chemin, sr=16000)
    print(f"   Dur√©e: {len(audio)/sr:.2f} secondes")
    print(f"   Fr√©quence d'√©chantillonnage: {sr} Hz")
    
    return audio, sr

def lire_texte_reference(chemin):
    """Lit le texte de r√©f√©rence"""
    with open(chemin, 'r', encoding='utf-8') as f:
        texte = f.read().strip()
    print(f"üìñ Texte de r√©f√©rence lu ({len(texte)} caract√®res)")
    return texte

# ============ PARTIE 5 : SEGMENTATION MANUELLE (pour d√©buter) ============
def segmenter_audio_simple(audio, sr, duree_segment=10):
    """
    D√©coupe l'audio en segments de dur√©e fixe
    (Plus simple que VAD pour commencer)
    """
    print("‚úÇÔ∏è D√©coupage de l'audio...")
    
    # Calculer la taille d'un segment en √©chantillons
    segment_samples = int(duree_segment * sr)
    
    segments = []
    n_segments = len(audio) // segment_samples + 1
    
    for i in range(n_segments):
        debut = i * segment_samples
        fin = min((i + 1) * segment_samples, len(audio))
        
        if fin - debut > sr * 0.5:  # Ignorer les segments trop courts (<0.5s)
            segment_audio = audio[debut:fin]
            segments.append({
                'id': i,
                'audio': segment_audio,
                'debut_temps': debut / sr,
                'fin_temps': fin / sr,
                'duree': (fin - debut) / sr
            })
    
    print(f"   {len(segments)} segments cr√©√©s")
    return segments

# ============ PARTIE 6 : TRANSCRIPTION ============
def transcrire_audio(chemin_audio):
    """Transcrit un fichier audio complet"""
    print(f"\nüé§ Transcription de {chemin_audio}...")
    
    # Transcription simple (tout l'audio d'un coup)
    resultat = transcriber(chemin_audio)
    transcription = resultat['text']
    
    print(f"üìù Transcription obtenue:")
    print(f"   '{transcription[:100]}...'" if len(transcription) > 100 else f"   '{transcription}'")
    
    return transcription

# ============ PARTIE 7 : CALCUL DU WER (simplifi√©) ============
def calculer_erreurs(transcription, reference):
    """Calcule le pourcentage d'erreurs simplement"""
    # Conversion en minuscules et suppression de la ponctuation
    import re
    
    def nettoyer_texte(texte):
        texte = texte.lower()
        texte = re.sub(r'[^\w\s]', '', texte)  # Enl√®ve ponctuation
        texte = re.sub(r'\s+', ' ', texte)     # Espaces multiples -> simple
        return texte.strip()
    
    trans_clean = nettoyer_texte(transcription)
    ref_clean = nettoyer_texte(reference)
    
    # S√©parer en mots
    mots_trans = trans_clean.split()
    mots_ref = ref_clean.split()
    
    # Calcul simple (approximatif)
    n_mots_ref = len(mots_ref)
    
    if n_mots_ref == 0:
        return {"erreur": 100.0, "details": "R√©f√©rence vide"}
    
    # Pour d√©buter, on fait une comparaison simple
    # Note: C'est une simplification, pas le vrai WER
    mots_corrects = sum(1 for i in range(min(len(mots_trans), len(mots_ref))) 
                       if mots_trans[i] == mots_ref[i])
    
    pourcentage_erreur = (1 - mots_corrects/n_mots_ref) * 100
    
    return {
        "erreur_approximative": pourcentage_erreur,
        "mots_reference": n_mots_ref,
        "mots_transcription": len(mots_trans),
        "mots_corrects": mots_corrects
    }

# ============ PARTIE 8 : VISUALISATION ============
def afficher_spectrogramme(audio, sr, titre):
    """Affiche un spectrogramme simple"""
    print(f"\nüìä Cr√©ation du spectrogramme pour {titre}...")
    
    plt.figure(figsize=(12, 4))
    
    # Cr√©er le spectrogramme
    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)
    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')
    
    plt.colorbar(format='%+2.0f dB')
    plt.title(f'Spectrogramme: {titre}')
    plt.xlabel('Temps (s)')
    plt.ylabel('Fr√©quence (Hz)')
    
    # Sauvegarder l'image
    plt.savefig(f'spectrogramme_{titre}.png', dpi=150, bbox_inches='tight')
    plt.show()
    print("‚úÖ Spectrogramme sauvegard√©!")

# ============ PARTIE 9 : EX√âCUTION PRINCIPALE ============
def main():
    """Fonction principale qui ex√©cute tout le lab"""
    print("\n" + "="*50)
    print("        LAB STT - D√âBUT DE L'EXP√âRIENCE")
    print("="*50)
    
    resultats = []
    
    # Pour chaque fichier audio
    for i, (audio_file, ref_file) in enumerate(zip(AUDIO_FILES, REF_FILES)):
        print(f"\n{'='*40}")
        print(f"EXP√âRIENCE {i+1}: {audio_file}")
        print(f"{'='*40}")
        
        try:
            # 1. Lire les fichiers
            audio, sr = lire_fichier_audio(audio_file)
            reference = lire_texte_reference(ref_file)
            
            # 2. Afficher le spectrogramme
            afficher_spectrogramme(audio, sr, f"test{i+1}")
            
            # 3. Transcrire
            transcription = transcrire_audio(audio_file)
            
            # 4. Calculer les erreurs
            erreurs = calculer_erreurs(transcription, reference)
            
            # 5. Afficher les r√©sultats
            print(f"\nüìä R√âSULTATS pour test{i+1}:")
            print(f"   Taux d'erreur approximatif: {erreurs['erreur_approximative']:.2f}%")
            print(f"   Mots dans la r√©f√©rence: {erreurs['mots_reference']}")
            print(f"   Mots dans la transcription: {erreurs['mots_transcription']}")
            print(f"   Mots corrects: {erreurs['mots_corrects']}")
            
            # Sauvegarder les r√©sultats
            resultats.append({
                'fichier': audio_file,
                'erreur': erreurs['erreur_approximative'],
                'transcription': transcription,
                'reference': reference
            })
            
        except Exception as e:
            print(f"‚ùå Erreur avec {audio_file}: {e}")
    
    # ============ R√âSUM√â FINAL ============
    print("\n" + "="*50)
    print("            R√âSUM√â DES R√âSULTATS")
    print("="*50)
    
    for i, res in enumerate(resultats):
        print(f"\nTest {i+1}:")
        print(f"  Fichier: {res['fichier']}")
        print(f"  Erreur: {res['erreur']:.2f}%")
    
    # Moyenne des erreurs
    if resultats:
        moyenne = sum(r['erreur'] for r in resultats) / len(resultats)
        print(f"\nüìà MOYENNE GLOBALE: {moyenne:.2f}% d'erreur")
    
    print("\n‚úÖ Lab termin√© avec succ√®s!")

# ============ LANCER LE LAB ============
if __name__ == "__main__":
    main()